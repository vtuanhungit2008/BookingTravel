import { OpenAI } from 'openai';
import { NextRequest, NextResponse } from 'next/server';
import prisma from '@/utils/db';


const openai = new OpenAI({
  apiKey: process.env.OPENROUTER_API_KEY!,
  baseURL: 'https://openrouter.ai/api/v1',
});

// üëâ Link ƒë·∫øn property
const formatProperties = (properties: any[]) => {
  return properties
    .map((prop, i) => {
      return `
üè° ${prop.name}
 ${prop.tagline}
- Qu·ªëc gia: ${prop.country}
- Lo·∫°i: ${prop.category}
- Gi√°: $${prop.price}/ƒë√™m
- Th√¥ng tin kh√°c: $${prop.description}
- S·ª©c ch·ª©a: ${prop.guests} kh√°ch, ${prop.bedrooms} ph√≤ng ng·ªß, ${prop.beds} gi∆∞·ªùng, ${prop.baths} ph√≤ng t·∫Øm
üîó [Xem chi ti·∫øt](http://localhost:3000/properties/${prop.id})`;
    })
    .join('');
};

export async function POST(req: NextRequest) {
  try {
    const { message } = await req.json();

    const properties = await prisma.property.findMany({
      take: 10,
      orderBy: { createdAt: 'desc' },
    });

    const systemPrompt = `
B·∫°n l√† tr·ª£ l√Ω AI chuy√™n t∆∞ v·∫•n ch·ªó ·ªü. D∆∞·ªõi ƒë√¢y l√† danh s√°ch ch·ªó ·ªü hi·ªán c√≥:

${formatProperties(properties)}

Khi ng∆∞·ªùi d√πng h·ªèi, h√£y ƒë·ªÅ xu·∫•t c√°c l·ª±a ch·ªçn ph√π h·ª£p k√®m link [Xem chi ti·∫øt].
`;

    const chat = await openai.chat.completions.create({
      model: 'openai/gpt-3.5-turbo',
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: message },
      ],
    });

    return NextResponse.json({ reply: chat.choices[0].message.content });
  } catch (err) {
    console.error('[Assistant Error]', err);
    return NextResponse.json({ error: 'L·ªói server' }, { status: 500 });
  }
}
