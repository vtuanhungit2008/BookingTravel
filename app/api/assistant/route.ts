import { OpenAI } from 'openai';
import { NextRequest, NextResponse } from 'next/server';
import db from '@/utils/db';

const openai = new OpenAI({
  apiKey: process.env.OPENROUTER_API_KEY!,
  baseURL: 'https://openrouter.ai/api/v1',
});

const formatProperties = (properties: any[]) => {
  return properties
    .map((prop) => `
### üè° ${prop.name}
![${prop.name}](${prop.image})

${prop.tagline}
- üåç Qu·ªëc gia: ${prop.country}
- üèß Lo·∫°i: ${prop.category}
- üí∞ Gi√°: $${prop.price}/ƒë√™m
- üë• S·ª©c ch·ª©a: ${prop.guests} kh√°ch, ${prop.bedrooms} ph√≤ng ng·ªß, ${prop.beds} gi∆∞·ªùng, ${prop.baths} ph√≤ng t·∫Øm 

üîó [Xem chi ti·∫øt](http://localhost:3000/properties/${prop.id})
`)
    .join('\n');
};

export async function POST(req: NextRequest) {
  try {
    const { message, history } = await req.json();

    const properties = await db.property.findMany({
      take: 15,
      orderBy: { createdAt: 'desc' },
    });

    const historyContext = history?.length
      ? history.map((m: any, i: number) => `L·∫ßn ${i + 1}: ${m.text}`).join('\n')
      : 'Kh√¥ng c√≥ l·ªãch s·ª≠.';

    const systemPrompt = `
B·∫°n l√† m·ªôt tr·ª£ l√Ω AI t∆∞ v·∫•n ch·ªó ·ªü.

D∆∞·ªõi ƒë√¢y l√† c√°c y√™u c·∫ßu tr∆∞·ªõc ƒë√¢y t·ª´ ng∆∞·ªùi d√πng:
${historyContext}

D∆∞·ªõi ƒë√¢y l√† y√™u c·∫ßu m·ªõi: "${message}"

H√£y:
1. Ph√¢n t√≠ch to√†n b·ªô nhu c·∫ßu c·ªßa ng∆∞·ªùi d√πng
2. ∆Øu ti√™n c√°c l·ª±a ch·ªçn ph√π h·ª£p v·ªõi xu h∆∞·ªõng c≈©
3. G·ª£i √Ω 3‚Äì5 ch·ªó ·ªü ph√π h·ª£p nh·∫•t t·ª´ danh s√°ch d∆∞·ªõi, k√®m ·∫£nh v√† link [Xem chi ti·∫øt].

${formatProperties(properties)}
`;

    const chat = await openai.chat.completions.create({
      model: 'openai/gpt-3.5-turbo',
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: message },
      ],
    });

    return NextResponse.json({ reply: chat.choices[0].message.content });
  } catch (err) {
    console.error('[Assistant Error]', err);
    return NextResponse.json({ error: 'L·ªói server' }, { status: 500 });
  }
}